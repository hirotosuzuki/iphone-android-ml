{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/furukawahidekazu/anaconda3/envs/turicreate/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/furukawahidekazu/anaconda3/envs/turicreate/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Materializing SFrame</pre>"
      ],
      "text/plain": [
       "Materializing SFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import turicreate as tc\n",
    "from glob import glob\n",
    "\n",
    "# labels.txtのデータセットの読み込み\n",
    "labels = tc.SFrame.read_csv('./HAPT Data Set/RawData/labels.txt', \n",
    "    delimiter=' ', header=False, verbose=False)\n",
    "labels = labels.rename({'X1': 'exp_id', 'X2': 'user_id', \n",
    "    'X3': 'activity_id', 'X4': 'start', 'X5': 'end'})\n",
    "\n",
    "# データセットの確認\n",
    "labels.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./HAPT Data Set/RawData/acc_exp01_user01.txt', './HAPT Data Set/RawData/acc_exp02_user01.txt', './HAPT Data Set/RawData/acc_exp03_user02.txt', './HAPT Data Set/RawData/acc_exp04_user02.txt', './HAPT Data Set/RawData/acc_exp05_user03.txt', './HAPT Data Set/RawData/acc_exp06_user03.txt', './HAPT Data Set/RawData/acc_exp07_user04.txt', './HAPT Data Set/RawData/acc_exp08_user04.txt', './HAPT Data Set/RawData/acc_exp09_user05.txt', './HAPT Data Set/RawData/acc_exp10_user05.txt', './HAPT Data Set/RawData/acc_exp11_user06.txt', './HAPT Data Set/RawData/acc_exp12_user06.txt', './HAPT Data Set/RawData/acc_exp13_user07.txt', './HAPT Data Set/RawData/acc_exp14_user07.txt', './HAPT Data Set/RawData/acc_exp15_user08.txt', './HAPT Data Set/RawData/acc_exp16_user08.txt', './HAPT Data Set/RawData/acc_exp17_user09.txt', './HAPT Data Set/RawData/acc_exp18_user09.txt', './HAPT Data Set/RawData/acc_exp19_user10.txt', './HAPT Data Set/RawData/acc_exp20_user10.txt', './HAPT Data Set/RawData/acc_exp21_user10.txt', './HAPT Data Set/RawData/acc_exp22_user11.txt', './HAPT Data Set/RawData/acc_exp23_user11.txt', './HAPT Data Set/RawData/acc_exp24_user12.txt', './HAPT Data Set/RawData/acc_exp25_user12.txt', './HAPT Data Set/RawData/acc_exp26_user13.txt', './HAPT Data Set/RawData/acc_exp27_user13.txt', './HAPT Data Set/RawData/acc_exp28_user14.txt', './HAPT Data Set/RawData/acc_exp29_user14.txt', './HAPT Data Set/RawData/acc_exp30_user15.txt', './HAPT Data Set/RawData/acc_exp31_user15.txt', './HAPT Data Set/RawData/acc_exp32_user16.txt', './HAPT Data Set/RawData/acc_exp33_user16.txt', './HAPT Data Set/RawData/acc_exp34_user17.txt', './HAPT Data Set/RawData/acc_exp35_user17.txt', './HAPT Data Set/RawData/acc_exp36_user18.txt', './HAPT Data Set/RawData/acc_exp37_user18.txt', './HAPT Data Set/RawData/acc_exp38_user19.txt', './HAPT Data Set/RawData/acc_exp39_user19.txt', './HAPT Data Set/RawData/acc_exp40_user20.txt', './HAPT Data Set/RawData/acc_exp41_user20.txt', './HAPT Data Set/RawData/acc_exp42_user21.txt', './HAPT Data Set/RawData/acc_exp43_user21.txt', './HAPT Data Set/RawData/acc_exp44_user22.txt', './HAPT Data Set/RawData/acc_exp45_user22.txt', './HAPT Data Set/RawData/acc_exp46_user23.txt', './HAPT Data Set/RawData/acc_exp47_user23.txt', './HAPT Data Set/RawData/acc_exp48_user24.txt', './HAPT Data Set/RawData/acc_exp49_user24.txt', './HAPT Data Set/RawData/acc_exp50_user25.txt', './HAPT Data Set/RawData/acc_exp51_user25.txt', './HAPT Data Set/RawData/acc_exp52_user26.txt', './HAPT Data Set/RawData/acc_exp53_user26.txt', './HAPT Data Set/RawData/acc_exp54_user27.txt', './HAPT Data Set/RawData/acc_exp55_user27.txt', './HAPT Data Set/RawData/acc_exp56_user28.txt', './HAPT Data Set/RawData/acc_exp57_user28.txt', './HAPT Data Set/RawData/acc_exp58_user29.txt', './HAPT Data Set/RawData/acc_exp59_user29.txt', './HAPT Data Set/RawData/acc_exp60_user30.txt', './HAPT Data Set/RawData/acc_exp61_user30.txt']\n",
      "['./HAPT Data Set/RawData/gyro_exp01_user01.txt', './HAPT Data Set/RawData/gyro_exp02_user01.txt', './HAPT Data Set/RawData/gyro_exp03_user02.txt', './HAPT Data Set/RawData/gyro_exp04_user02.txt', './HAPT Data Set/RawData/gyro_exp05_user03.txt', './HAPT Data Set/RawData/gyro_exp06_user03.txt', './HAPT Data Set/RawData/gyro_exp07_user04.txt', './HAPT Data Set/RawData/gyro_exp08_user04.txt', './HAPT Data Set/RawData/gyro_exp09_user05.txt', './HAPT Data Set/RawData/gyro_exp10_user05.txt', './HAPT Data Set/RawData/gyro_exp11_user06.txt', './HAPT Data Set/RawData/gyro_exp12_user06.txt', './HAPT Data Set/RawData/gyro_exp13_user07.txt', './HAPT Data Set/RawData/gyro_exp14_user07.txt', './HAPT Data Set/RawData/gyro_exp15_user08.txt', './HAPT Data Set/RawData/gyro_exp16_user08.txt', './HAPT Data Set/RawData/gyro_exp17_user09.txt', './HAPT Data Set/RawData/gyro_exp18_user09.txt', './HAPT Data Set/RawData/gyro_exp19_user10.txt', './HAPT Data Set/RawData/gyro_exp20_user10.txt', './HAPT Data Set/RawData/gyro_exp21_user10.txt', './HAPT Data Set/RawData/gyro_exp22_user11.txt', './HAPT Data Set/RawData/gyro_exp23_user11.txt', './HAPT Data Set/RawData/gyro_exp24_user12.txt', './HAPT Data Set/RawData/gyro_exp25_user12.txt', './HAPT Data Set/RawData/gyro_exp26_user13.txt', './HAPT Data Set/RawData/gyro_exp27_user13.txt', './HAPT Data Set/RawData/gyro_exp28_user14.txt', './HAPT Data Set/RawData/gyro_exp29_user14.txt', './HAPT Data Set/RawData/gyro_exp30_user15.txt', './HAPT Data Set/RawData/gyro_exp31_user15.txt', './HAPT Data Set/RawData/gyro_exp32_user16.txt', './HAPT Data Set/RawData/gyro_exp33_user16.txt', './HAPT Data Set/RawData/gyro_exp34_user17.txt', './HAPT Data Set/RawData/gyro_exp35_user17.txt', './HAPT Data Set/RawData/gyro_exp36_user18.txt', './HAPT Data Set/RawData/gyro_exp37_user18.txt', './HAPT Data Set/RawData/gyro_exp38_user19.txt', './HAPT Data Set/RawData/gyro_exp39_user19.txt', './HAPT Data Set/RawData/gyro_exp40_user20.txt', './HAPT Data Set/RawData/gyro_exp41_user20.txt', './HAPT Data Set/RawData/gyro_exp42_user21.txt', './HAPT Data Set/RawData/gyro_exp43_user21.txt', './HAPT Data Set/RawData/gyro_exp44_user22.txt', './HAPT Data Set/RawData/gyro_exp45_user22.txt', './HAPT Data Set/RawData/gyro_exp46_user23.txt', './HAPT Data Set/RawData/gyro_exp47_user23.txt', './HAPT Data Set/RawData/gyro_exp48_user24.txt', './HAPT Data Set/RawData/gyro_exp49_user24.txt', './HAPT Data Set/RawData/gyro_exp50_user25.txt', './HAPT Data Set/RawData/gyro_exp51_user25.txt', './HAPT Data Set/RawData/gyro_exp52_user26.txt', './HAPT Data Set/RawData/gyro_exp53_user26.txt', './HAPT Data Set/RawData/gyro_exp54_user27.txt', './HAPT Data Set/RawData/gyro_exp55_user27.txt', './HAPT Data Set/RawData/gyro_exp56_user28.txt', './HAPT Data Set/RawData/gyro_exp57_user28.txt', './HAPT Data Set/RawData/gyro_exp58_user29.txt', './HAPT Data Set/RawData/gyro_exp59_user29.txt', './HAPT Data Set/RawData/gyro_exp60_user30.txt', './HAPT Data Set/RawData/gyro_exp61_user30.txt']\n"
     ]
    }
   ],
   "source": [
    "#　aac_*.txtとgyro_*.txtのファイル一覧の取得\n",
    "acc_files = sorted(glob('./HAPT Data Set/RawData/acc_*.txt'))\n",
    "gyro_files = sorted(glob('./HAPT Data Set/RawData/gyro_*.txt'))\n",
    "\n",
    "# ファイル一覧の確認\n",
    "print(acc_files)\n",
    "print(gyro_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_fileの行番号から活動IDを取得\n",
    "def find_label_for_containing_interval(intervals, index):\n",
    "    # indexがstart以上end以下\n",
    "    containing_interval = intervals[:, 0][(intervals[:, 1] <= index) & (index <= intervals[:, 2])]\n",
    "    if len(containing_interval) == 1:\n",
    "        return containing_interval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Materializing SFrame</pre>"
      ],
      "text/plain": [
       "Materializing SFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 最終のデータセットの作成\n",
    "data = tc.SFrame()\n",
    "for acc_file, gyro_file in zip(acc_files, gyro_files):\n",
    "    # 実験IDの抽出\n",
    "    exp_id = int(acc_file.split('_')[1][-2:])\n",
    "\n",
    "    # acc_fileのデータセットの作成し、exp_id列を追加\n",
    "    sf = tc.SFrame.read_csv(acc_file, delimiter=' ', header=False, verbose=False)\n",
    "    sf = sf.rename({'X1': 'acc_x', 'X2': 'acc_y', 'X3': 'acc_z'})\n",
    "\n",
    "    # gyro_fileのデータセットを作成し、acc_fileのデータセットと連結\n",
    "    gyro_sf = tc.SFrame.read_csv(gyro_file, delimiter=' ', header=False, verbose=False)\n",
    "    gyro_sf = gyro_sf.rename({'X1': 'gyro_x', 'X2': 'gyro_y', 'X3': 'gyro_z'})\n",
    "    sf = sf.add_columns(gyro_sf)\n",
    "    \n",
    "    # 実験IDをexp_id列に追加\n",
    "    sf['exp_id'] = exp_id\n",
    "\n",
    "    # 行番号をid列に追加\n",
    "    sf = sf.add_row_number()\n",
    "\n",
    "    # labelsから同じ実験IDのactivity_id、start、endを取得\n",
    "    exp_labels = labels[labels['exp_id'] == exp_id][['activity_id', 'start', 'end']].to_numpy()\n",
    "\n",
    "    # 活動IDをactivity_id列に追加\n",
    "    sf['activity_id'] = sf['id'].apply(lambda index: find_label_for_containing_interval(exp_labels, index))\n",
    "\n",
    "    # id列の削除\n",
    "    sf = sf.remove_columns(['id'])\n",
    "\n",
    "    # acc_fileのデータセットを最終のデータセットに追加\n",
    "    data = data.append(sf)\n",
    "    \n",
    "# 最終のデータセットの確認\n",
    "data.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Materializing SFrame</pre>"
      ],
      "text/plain": [
       "Materializing SFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6種類の活動IDでフィルタリング\n",
    "target_map = {\n",
    "    1.: 'walking',\n",
    "    2.: 'climbing_upstairs',\n",
    "    3.: 'climbing_downstairs',\n",
    "    4.: 'sitting',\n",
    "    5.: 'standing',\n",
    "    6.: 'laying'\n",
    "}\n",
    "data = data.filter_by(list(target_map.keys()), 'activity_id')\n",
    "\n",
    "# 活動ラベルをactivity列に追加\n",
    "data['activity'] = data['activity_id'].apply(lambda x: target_map[x])\n",
    "\n",
    "# activity_id列を削除\n",
    "data = data.remove_column('activity_id')\n",
    "\n",
    "# 最終のデータセットの確認\n",
    "data.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has less than the minimum of 100 sessions required for train-validation split. Continuing without validation set\n"
     ]
    }
   ],
   "source": [
    "# 訓練データと評価データの分割\n",
    "train_data, test_data = tc.activity_classifier.util.random_split_by_session(\n",
    "    data, session_id='exp_id', fraction=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has less than the minimum of 100 sessions required for train-validation split. Continuing without validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Pre-processing 748406 samples...</pre>"
      ],
      "text/plain": [
       "Pre-processing 748406 samples..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Using sequences of size 1000 for model creation.</pre>"
      ],
      "text/plain": [
       "Using sequences of size 1000 for model creation."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Processed a total of 61 sessions.</pre>"
      ],
      "text/plain": [
       "Processed a total of 61 sessions."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU to create model\n",
      "+----------------+----------------+----------------+----------------+\n",
      "| Iteration      | Train Accuracy | Train Loss     | Elapsed Time   |\n",
      "+----------------+----------------+----------------+----------------+\n",
      "| 1              | 0.655          | 0.900          | 1.0            |\n",
      "| 2              | 0.816          | 0.499          | 2.1            |\n",
      "| 3              | 0.862          | 0.380          | 3.2            |\n",
      "| 4              | 0.881          | 0.319          | 4.2            |\n",
      "| 5              | 0.894          | 0.278          | 5.3            |\n",
      "| 6              | 0.907          | 0.249          | 6.4            |\n",
      "| 7              | 0.918          | 0.222          | 7.6            |\n",
      "| 8              | 0.920          | 0.212          | 8.6            |\n",
      "| 9              | 0.923          | 0.200          | 9.7            |\n",
      "| 10             | 0.927          | 0.184          | 10.8           |\n",
      "+----------------+----------------+----------------+----------------+\n",
      "Training complete\n",
      "Total Time Spent: 10.7847s\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "model = tc.activity_classifier.create(\n",
    "    train_data, session_id='exp_id', target='activity', prediction_window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価\n",
    "metrics = model.evaluate(train_data) # test_dataがNoneのため\n",
    "\n",
    "# 評価データの正解率\n",
    "print(metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turi Createモデルの保存\n",
    "model.save('./ActivityClassification.model')\n",
    "\n",
    "# Core ML形式のモデルの保存\n",
    "model.export_coreml('./ActivityClassification.mlmodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
